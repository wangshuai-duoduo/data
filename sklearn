无论利用机器学习算法进行回归、分类或者聚类时，评价指标，即检验机器学习模型效果的定量指标，都是一个不可避免且十分重要的问题
一、有三种不同的方法来评估一个模型的预测质量：https://www.cnblogs.com/harvey888/p/6964741.html

estimator的score方法：sklearn中的estimator都具有一个score方法，它提供了一个缺省的评估法则来解决问题。
Scoring参数：使用cross-validation的模型评估工具，依赖于内部的scoring策略。见下。
Metric函数：metrics模块实现了一些函数，用来评估预测误差。见下。

1、scoring参数-----模型选择和评估工具，使用scoring参数来控制你的estimator估计量的好坏
  1.1
    对于大多数case而说，你可以设计一个使用scoring参数的scorer对象；下面展示了所有可能的值。所有的scorer对象都遵循：高得分，更好效果。
    如果从mean_absolute_error 和mean_squared_error（它计算了模型与数据间的距离）返回的得分将被忽略
    
  1.2从metric函数定义你的scoring策略
    以_score结尾的函数，返回一个最大值，越高越好
    以_error结尾的函数，返回一个最小值，越小越好；如果使用make_scorer来创建scorer时，将greater_is_better设为False
  1.3












1、scikit-learn.metrics导入与调用
  一、from sklearn.metrics import 评价指标函数名称
      例如：from sklearn.metrics import r2_score
           from sklearn.metrics import mean_squared_error 
              调用方式为：直接使用函数名调用
              计算均方误差mean squared error
                mse = mean_squared_error(y_test, y_pre)
               算回归的决定系数R2
                R2 = r2_score(y_test,y_pre)
                
    二、回归指标
1.explained_variance_score(y_true, y_pred, sample_weight=None, multioutput='uniform_average')：回归方差(反应自变量与因变量之间的相关程度)

2.mean_absolute_error(y_true, y_pred, sample_weight=None, multioutput='uniform_average')：平均绝对误差

3.mean_squared_error(y_true, y_pred, sample_weight=None, multioutput='uniform_average')：均方差
 
4.median_absolute_error(y_true, y_pred)   中值绝对误差

5.r2_score(y_true, y_pred, sample_weight=None, multioutput='uniform_average')  ：R平方值


    三、分类指标
    
    1.accuracy_score(y_true,y_pre) : 精度 
    
2.auc(x, y, reorder=False) : ROC曲线下的面积;较大的AUC代表了较好的performance。

3.average_precision_score(y_true, y_score, average='macro', sample_weight=None):根据预测得分计算平均精度(AP)

4.brier_score_loss(y_true, y_prob, sample_weight=None, pos_label=None):The smaller the Brier score, the better.

5.confusion_matrix(y_true, y_pred, labels=None, sample_weight=None):通过计算混淆矩阵来评估分类的准确性 返回混淆矩阵

6.f1_score(y_true, y_pred, labels=None, pos_label=1, average='binary', sample_weight=None): F1值

　　F1 = 2 * (precision * recall) / (precision + recall) precision(查准率)=TP/(TP+FP) recall(查全率)=TP/(TP+FN)

 7.log_loss(y_true, y_pred, eps=1e-15, normalize=True, sample_weight=None, labels=None)：对数损耗，又称逻辑损耗或交叉熵损耗

8.precision_score(y_true, y_pred, labels=None, pos_label=1, average='binary',) ：查准率或者精度； precision(查准率)=TP/(TP+FP)

9.recall_score(y_true, y_pred, labels=None, pos_label=1, average='binary', sample_weight=None)：查全率 ；recall(查全率)=TP/(TP+FN)

10.roc_auc_score(y_true, y_score, average='macro', sample_weight=None)：计算ROC曲线下的面积就是AUC的值，the larger the better

11.roc_curve(y_true, y_score, pos_label=None, sample_weight=None, drop_intermediate=True)；计算ROC曲线的横纵坐标值，TPR，FPR

　　TPR = TP/(TP+FN) = recall(真正例率，敏感度)       FPR = FP/(FP+TN)(假正例率，1-特异性)


